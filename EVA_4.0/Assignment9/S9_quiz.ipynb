{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled23.ipynb",
      "provenance": [],
      "mount_file_id": "1k-pPkHB42j4JOcZYHmXfVXXMdmDdefsg",
      "authorship_tag": "ABX9TyOZbdH3XtEygaB4Vvf/Of7n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubhamk16/Deep_learning/blob/master/S9_quiz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UWVGh8A24CD",
        "colab_type": "code",
        "outputId": "203120c6-b2de-4f66-f828-3cf06a52c3b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tv3MbhFL24zM",
        "colab_type": "code",
        "outputId": "a9b15190-d2bb-408f-88b0-e8e271cc68e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/gdrive/My Drive/TSAI_EVA_4.0/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/TSAI_EVA_4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsw5J2Vr3SdW",
        "colab_type": "code",
        "outputId": "0ea147ed-ae21-4009-fd90-dc34fa09945e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import datetime\n",
        "datetime.datetime.now()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datetime.datetime(2020, 3, 22, 3, 12, 16, 197647)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTGYDvWS3WPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import albumentations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sp4hnwUT3iwr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R69noIGM3aOI",
        "colab_type": "code",
        "outputId": "8525a0ab-4104-4a89-94af-776ff7284363",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import transform\n",
        "\n",
        "trainloader = transform.trainloader\n",
        "testloader =  transform.testloader\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA Available? True\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KR3jz8OG3gaq",
        "colab_type": "code",
        "outputId": "b9c1efe5-f27f-4e39-a25a-7eb30fe11867",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 924
        }
      },
      "source": [
        "from Model import QuizDNN\n",
        "\n",
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "net = QuizDNN.Net().to(device)\n",
        "summary(net, input_size=(3, 32, 32))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n",
            "cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 32, 32]              96\n",
            "            Conv2d-2           [-1, 32, 32, 32]             864\n",
            "       BatchNorm2d-3           [-1, 32, 32, 32]              64\n",
            "              ReLU-4           [-1, 32, 32, 32]               0\n",
            "           Dropout-5           [-1, 32, 32, 32]               0\n",
            "            Conv2d-6           [-1, 32, 32, 32]           9,216\n",
            "       BatchNorm2d-7           [-1, 32, 32, 32]              64\n",
            "              ReLU-8           [-1, 32, 32, 32]               0\n",
            "           Dropout-9           [-1, 32, 32, 32]               0\n",
            "        MaxPool2d-10           [-1, 32, 16, 16]               0\n",
            "           Conv2d-11           [-1, 64, 16, 16]           2,048\n",
            "           Conv2d-12           [-1, 64, 16, 16]          18,432\n",
            "      BatchNorm2d-13           [-1, 64, 16, 16]             128\n",
            "             ReLU-14           [-1, 64, 16, 16]               0\n",
            "          Dropout-15           [-1, 64, 16, 16]               0\n",
            "           Conv2d-16           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-17           [-1, 64, 16, 16]             128\n",
            "             ReLU-18           [-1, 64, 16, 16]               0\n",
            "          Dropout-19           [-1, 64, 16, 16]               0\n",
            "           Conv2d-20           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-21           [-1, 64, 16, 16]             128\n",
            "             ReLU-22           [-1, 64, 16, 16]               0\n",
            "          Dropout-23           [-1, 64, 16, 16]               0\n",
            "        MaxPool2d-24             [-1, 64, 8, 8]               0\n",
            "           Conv2d-25            [-1, 128, 8, 8]           8,192\n",
            "           Conv2d-26            [-1, 128, 8, 8]          73,728\n",
            "      BatchNorm2d-27            [-1, 128, 8, 8]             256\n",
            "             ReLU-28            [-1, 128, 8, 8]               0\n",
            "          Dropout-29            [-1, 128, 8, 8]               0\n",
            "           Conv2d-30            [-1, 128, 8, 8]         147,456\n",
            "      BatchNorm2d-31            [-1, 128, 8, 8]             256\n",
            "             ReLU-32            [-1, 128, 8, 8]               0\n",
            "          Dropout-33            [-1, 128, 8, 8]               0\n",
            "           Conv2d-34            [-1, 128, 8, 8]         147,456\n",
            "      BatchNorm2d-35            [-1, 128, 8, 8]             256\n",
            "             ReLU-36            [-1, 128, 8, 8]               0\n",
            "          Dropout-37            [-1, 128, 8, 8]               0\n",
            "        AvgPool2d-38            [-1, 128, 1, 1]               0\n",
            "           Linear-39                   [-1, 10]           1,290\n",
            "================================================================\n",
            "Total params: 483,786\n",
            "Trainable params: 483,786\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 4.78\n",
            "Params size (MB): 1.85\n",
            "Estimated Total Size (MB): 6.64\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-qdf_RW4Bgo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import torch.nn as nn\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.0011, momentum=0.9, weight_decay=0.0001)\n",
        "#scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.001, max_lr=0.1)\n",
        "scheduler = StepLR(optimizer, step_size=10, gamma=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTKNlPyg8B8F",
        "colab_type": "code",
        "outputId": "421b9e3b-e9ce-47fb-ed1c-af868532496d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "import train\n",
        "import test\n",
        "test_acc = []\n",
        "train_acc = []\n",
        "for epoch in range(25):  # loop over the dataset multiple times\n",
        "    if epoch>10:\n",
        "      scheduler.step()\n",
        "    for param_group in optimizer.param_groups:\n",
        "      print(\"lr= \",param_group['lr'])\n",
        "    train_acc.append(train.train(net, device, trainloader, optimizer, criterion, epoch))\n",
        "    test_acc.append(test.test(net, device, testloader))\n",
        "print('Finished Training')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch= 4 Loss=nan Batch_id=371 Accuracy=8.59:  95%|█████████▍| 371/391 [00:19<00:01, 17.86it/s] \u001b[A\n",
            "Epoch= 4 Loss=nan Batch_id=372 Accuracy=12.50:  95%|█████████▌| 372/391 [00:19<00:01, 17.86it/s]\u001b[A\n",
            "Epoch= 4 Loss=nan Batch_id=372 Accuracy=12.50:  95%|█████████▌| 373/391 [00:19<00:00, 18.71it/s]\u001b[A\n",
            "Epoch= 4 Loss=nan Batch_id=372 Accuracy=12.50:  95%|█████████▌| 373/391 [00:19<00:00, 18.57it/s]\u001b[A\n",
            "Epoch= 4 Loss=nan Batch_id=373 Accuracy=12.50:  95%|█████████▌| 373/391 [00:19<00:00, 18.57it/s]\u001b[A\n",
            "Epoch= 4 Loss=nan Batch_id=374 Accuracy=7.03:  96%|█████████▌| 374/391 [00:19<00:00, 18.57it/s] \u001b[A\n",
            "Epoch= 4 Loss=nan Batch_id=374 Accuracy=7.03:  96%|█████████▌| 375/391 [00:19<00:00, 18.57it/s]\u001b[A\n",
            "Epoch= 4 Loss=nan Batch_id=374 Accuracy=7.03:  96%|█████████▌| 375/391 [00:19<00:00, 18.32it/s]\u001b[A\n",
            "Epoch= 4 Loss=nan Batch_id=375 Accuracy=14.84:  96%|█████████▌| 375/391 [00:19<00:00, 18.32it/s]\u001b[A\n",
            "Epoch= 4 Loss=nan Batch_id=376 Accuracy=7.81:  96%|█████████▌| 376/391 [00:19<00:00, 18.32it/s] \u001b[A\n",
            "Epoch= 4 Loss=nan Batch_id=377 Accuracy=9.38:  96%|█████████▋| 377/391 [00:19<00:00, 18.32it/s]\u001b[A\n",
            "Epoch= 4 Loss=nan Batch_id=377 Accuracy=9.38:  97%|█████████▋| 378/391 [00:19<00:00, 18.84it/s]\u001b[A\n",
            "Epoch= 4 Loss=nan Batch_id=377 Accuracy=9.38:  97%|█████████▋| 378/391 [00:20<00:00, 18.49it/s]\u001b[A\n",
            "Epoch= 4 Loss=nan Batch_id=378 Accuracy=6.25:  97%|█████████▋| 378/391 [00:20<00:00, 18.49it/s]\u001b[A\n",
            "Epoch= 4 Loss=nan Batch_id=379 Accuracy=12.50:  97%|█████████▋| 379/391 [00:20<00:00, 18.49it/s]\u001b[A\n",
            "Epoch= 4 Loss=nan Batch_id=379 Accuracy=12.50:  97%|█████████▋| 380/391 [00:20<00:00, 17.91it/s]\u001b[A\n",
            "Epoch= 4 Loss=nan Batch_id=379 Accuracy=12.50:  97%|█████████▋| 380/391 [00:20<00:00, 17.74it/s]\u001b[A\n",
            "Epoch= 4 Loss=nan Batch_id=380 Accuracy=5.47:  97%|█████████▋| 380/391 [00:20<00:00, 17.74it/s] \u001b[A\n",
            "Epoch= 4 Loss=nan Batch_id=381 Accuracy=8.59:  97%|█████████▋| 381/391 [00:20<00:00, 17.74it/s]\u001b[A\n",
            "Epoch= 4 Loss=nan Batch_id=381 Accuracy=8.59:  98%|█████████▊| 382/391 [00:20<00:00, 17.91it/s]\u001b[A\n",
            "Epoch= 4 Loss=nan Batch_id=381 Accuracy=8.59:  98%|█████████▊| 382/391 [00:20<00:00, 17.72it/s]\u001b[A\n",
            "Epoch= 4 Loss=nan Batch_id=382 Accuracy=10.94:  98%|█████████▊| 382/391 [00:20<00:00, 17.72it/s]\u001b[A\n",
            "Epoch= 4 Loss=nan Batch_id=383 Accuracy=10.16:  98%|█████████▊| 383/391 [00:20<00:00, 17.72it/s]\u001b[A\n",
            "Epoch= 4 Loss=nan Batch_id=383 Accuracy=10.16:  98%|█████████▊| 384/391 [00:20<00:00, 18.23it/s]\u001b[A\n",
            "Epoch= 4 Loss=nan Batch_id=383 Accuracy=10.16:  98%|█████████▊| 384/391 [00:20<00:00, 18.04it/s]\u001b[A\n",
            "Epoch= 4 Loss=nan Batch_id=384 Accuracy=10.16:  98%|█████████▊| 384/391 [00:20<00:00, 18.04it/s]\u001b[A\n",
            "Epoch= 4 Loss=nan Batch_id=385 Accuracy=10.16:  98%|█████████▊| 385/391 [00:20<00:00, 18.04it/s]\u001b[A\n",
            "Epoch= 4 Loss=nan Batch_id=386 Accuracy=10.16:  99%|█████████▊| 386/391 [00:20<00:00, 18.04it/s]\u001b[A\n",
            "Epoch= 4 Loss=nan Batch_id=386 Accuracy=10.16:  99%|█████████▉| 387/391 [00:20<00:00, 19.47it/s]\u001b[A\n",
            "Epoch= 4 Loss=nan Batch_id=386 Accuracy=10.16:  99%|█████████▉| 387/391 [00:20<00:00, 19.39it/s]\u001b[A\n",
            "Epoch= 4 Loss=nan Batch_id=387 Accuracy=8.59:  99%|█████████▉| 387/391 [00:20<00:00, 19.39it/s] \u001b[A\n",
            "Epoch= 4 Loss=nan Batch_id=388 Accuracy=13.28:  99%|█████████▉| 388/391 [00:20<00:00, 19.39it/s]\u001b[A\n",
            "Epoch= 4 Loss=nan Batch_id=389 Accuracy=6.25:  99%|█████████▉| 389/391 [00:20<00:00, 19.39it/s] \u001b[A\n",
            "Epoch= 4 Loss=nan Batch_id=389 Accuracy=6.25: 100%|█████████▉| 390/391 [00:20<00:00, 20.89it/s]\u001b[A\n",
            "Epoch= 4 Loss=nan Batch_id=389 Accuracy=6.25: 100%|█████████▉| 390/391 [00:20<00:00, 20.79it/s]\u001b[A\n",
            "Epoch= 4 Loss=nan Batch_id=390 Accuracy=16.25: 100%|██████████| 391/391 [00:20<00:00, 18.87it/s]\n",
            "\n",
            "  0%|          | 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|▏         | 1/79 [00:00<00:22,  3.53it/s]\u001b[A\n",
            "  8%|▊         | 6/79 [00:00<00:14,  4.89it/s]\u001b[A\n",
            " 13%|█▎        | 10/79 [00:00<00:10,  6.63it/s]\u001b[A\n",
            " 16%|█▋        | 13/79 [00:00<00:07,  8.59it/s]\u001b[A\n",
            " 22%|██▏       | 17/79 [00:00<00:05, 10.98it/s]\u001b[A\n",
            " 27%|██▋       | 21/79 [00:00<00:04, 13.74it/s]\u001b[A\n",
            " 32%|███▏      | 25/79 [00:00<00:03, 16.95it/s]\u001b[A\n",
            " 37%|███▋      | 29/79 [00:01<00:02, 19.43it/s]\u001b[A\n",
            " 42%|████▏     | 33/79 [00:01<00:02, 22.31it/s]\u001b[A\n",
            " 47%|████▋     | 37/79 [00:01<00:01, 23.99it/s]\u001b[A\n",
            " 52%|█████▏    | 41/79 [00:01<00:01, 26.41it/s]\u001b[A\n",
            " 58%|█████▊    | 46/79 [00:01<00:01, 30.01it/s]\u001b[A\n",
            " 65%|██████▍   | 51/79 [00:01<00:00, 33.29it/s]\u001b[A\n",
            " 70%|██████▉   | 55/79 [00:01<00:00, 33.05it/s]\u001b[A\n",
            " 75%|███████▍  | 59/79 [00:01<00:00, 34.78it/s]\u001b[A\n",
            " 81%|████████  | 64/79 [00:02<00:00, 35.73it/s]\u001b[A\n",
            " 86%|████████▌ | 68/79 [00:02<00:00, 34.75it/s]\u001b[A\n",
            " 91%|█████████ | 72/79 [00:02<00:00, 34.71it/s]\u001b[A\n",
            "100%|██████████| 79/79 [00:02<00:00, 31.30it/s]\n",
            "\n",
            "  0%|          | 0/391 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 10 %\n",
            "lr=  0.0011\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch= 5 Loss=nan Batch_id=0 Accuracy=10.94:   0%|          | 0/391 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=0 Accuracy=10.94:   0%|          | 1/391 [00:00<02:15,  2.87it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=0 Accuracy=10.94:   0%|          | 1/391 [00:00<02:17,  2.84it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=1 Accuracy=13.28:   0%|          | 1/391 [00:00<02:17,  2.84it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=2 Accuracy=10.94:   1%|          | 2/391 [00:00<02:17,  2.84it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=3 Accuracy=8.59:   1%|          | 3/391 [00:00<02:16,  2.84it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=3 Accuracy=8.59:   1%|          | 4/391 [00:00<01:42,  3.79it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=3 Accuracy=8.59:   1%|          | 4/391 [00:00<01:42,  3.79it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=4 Accuracy=10.16:   1%|          | 4/391 [00:00<01:42,  3.79it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=5 Accuracy=15.62:   1%|▏         | 5/391 [00:00<01:41,  3.79it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=5 Accuracy=15.62:   2%|▏         | 6/391 [00:00<01:17,  4.95it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=5 Accuracy=15.62:   2%|▏         | 6/391 [00:00<01:17,  4.94it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=6 Accuracy=10.16:   2%|▏         | 6/391 [00:00<01:17,  4.94it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=7 Accuracy=14.84:   2%|▏         | 7/391 [00:00<01:17,  4.94it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=7 Accuracy=14.84:   2%|▏         | 8/391 [00:00<01:01,  6.21it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=7 Accuracy=14.84:   2%|▏         | 8/391 [00:00<01:01,  6.19it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=8 Accuracy=6.25:   2%|▏         | 8/391 [00:00<01:01,  6.19it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=9 Accuracy=12.50:   2%|▏         | 9/391 [00:00<01:01,  6.19it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=10 Accuracy=17.19:   3%|▎         | 10/391 [00:00<01:01,  6.19it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=10 Accuracy=17.19:   3%|▎         | 11/391 [00:00<00:48,  7.89it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=10 Accuracy=17.19:   3%|▎         | 11/391 [00:00<00:48,  7.87it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=11 Accuracy=5.47:   3%|▎         | 11/391 [00:00<00:48,  7.87it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=12 Accuracy=8.59:   3%|▎         | 12/391 [00:01<00:48,  7.87it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=12 Accuracy=8.59:   3%|▎         | 13/391 [00:01<00:39,  9.59it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=12 Accuracy=8.59:   3%|▎         | 13/391 [00:01<00:39,  9.55it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=13 Accuracy=10.16:   3%|▎         | 13/391 [00:01<00:39,  9.55it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=14 Accuracy=17.19:   4%|▎         | 14/391 [00:01<00:39,  9.55it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=15 Accuracy=13.28:   4%|▍         | 15/391 [00:01<00:39,  9.55it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=15 Accuracy=13.28:   4%|▍         | 16/391 [00:01<00:32, 11.43it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=15 Accuracy=13.28:   4%|▍         | 16/391 [00:01<00:33, 11.34it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=16 Accuracy=7.81:   4%|▍         | 16/391 [00:01<00:33, 11.34it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=17 Accuracy=13.28:   4%|▍         | 17/391 [00:01<00:32, 11.34it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=18 Accuracy=7.81:   5%|▍         | 18/391 [00:01<00:32, 11.34it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=18 Accuracy=7.81:   5%|▍         | 19/391 [00:01<00:27, 13.32it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=18 Accuracy=7.81:   5%|▍         | 19/391 [00:01<00:28, 13.27it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=19 Accuracy=8.59:   5%|▍         | 19/391 [00:01<00:28, 13.27it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=20 Accuracy=10.16:   5%|▌         | 20/391 [00:01<00:27, 13.27it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=21 Accuracy=4.69:   5%|▌         | 21/391 [00:01<00:27, 13.27it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=21 Accuracy=4.69:   6%|▌         | 22/391 [00:01<00:24, 14.90it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=21 Accuracy=4.69:   6%|▌         | 22/391 [00:01<00:24, 14.82it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=22 Accuracy=10.16:   6%|▌         | 22/391 [00:01<00:24, 14.82it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=23 Accuracy=4.69:   6%|▌         | 23/391 [00:01<00:24, 14.82it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=24 Accuracy=9.38:   6%|▌         | 24/391 [00:01<00:24, 14.82it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=24 Accuracy=9.38:   6%|▋         | 25/391 [00:01<00:21, 16.68it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=24 Accuracy=9.38:   6%|▋         | 25/391 [00:01<00:22, 16.57it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=25 Accuracy=7.81:   6%|▋         | 25/391 [00:01<00:22, 16.57it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=26 Accuracy=12.50:   7%|▋         | 26/391 [00:01<00:22, 16.57it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=27 Accuracy=7.03:   7%|▋         | 27/391 [00:01<00:21, 16.57it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=27 Accuracy=7.03:   7%|▋         | 28/391 [00:01<00:21, 17.26it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=27 Accuracy=7.03:   7%|▋         | 28/391 [00:01<00:21, 17.14it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=28 Accuracy=10.16:   7%|▋         | 28/391 [00:01<00:21, 17.14it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=29 Accuracy=8.59:   7%|▋         | 29/391 [00:01<00:21, 17.14it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=30 Accuracy=8.59:   8%|▊         | 30/391 [00:01<00:21, 17.14it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=30 Accuracy=8.59:   8%|▊         | 31/391 [00:01<00:20, 17.22it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=30 Accuracy=8.59:   8%|▊         | 31/391 [00:01<00:21, 17.10it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=31 Accuracy=9.38:   8%|▊         | 31/391 [00:01<00:21, 17.10it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=32 Accuracy=14.06:   8%|▊         | 32/391 [00:02<00:20, 17.10it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=33 Accuracy=8.59:   8%|▊         | 33/391 [00:02<00:20, 17.10it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=33 Accuracy=8.59:   9%|▊         | 34/391 [00:02<00:19, 17.95it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=33 Accuracy=8.59:   9%|▊         | 34/391 [00:02<00:19, 17.86it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=34 Accuracy=10.16:   9%|▊         | 34/391 [00:02<00:19, 17.86it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=35 Accuracy=9.38:   9%|▉         | 35/391 [00:02<00:19, 17.86it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=35 Accuracy=9.38:   9%|▉         | 36/391 [00:02<00:20, 17.60it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=35 Accuracy=9.38:   9%|▉         | 36/391 [00:02<00:20, 17.48it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=36 Accuracy=10.94:   9%|▉         | 36/391 [00:02<00:20, 17.48it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=37 Accuracy=9.38:   9%|▉         | 37/391 [00:02<00:20, 17.48it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=38 Accuracy=7.03:  10%|▉         | 38/391 [00:02<00:20, 17.48it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=38 Accuracy=7.03:  10%|▉         | 39/391 [00:02<00:19, 18.01it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=38 Accuracy=7.03:  10%|▉         | 39/391 [00:02<00:19, 17.80it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=39 Accuracy=13.28:  10%|▉         | 39/391 [00:02<00:19, 17.80it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=40 Accuracy=10.16:  10%|█         | 40/391 [00:02<00:19, 17.80it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=41 Accuracy=13.28:  10%|█         | 41/391 [00:02<00:19, 17.80it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=41 Accuracy=13.28:  11%|█         | 42/391 [00:02<00:18, 18.42it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=41 Accuracy=13.28:  11%|█         | 42/391 [00:02<00:19, 18.33it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=42 Accuracy=11.72:  11%|█         | 42/391 [00:02<00:19, 18.33it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=43 Accuracy=9.38:  11%|█         | 43/391 [00:02<00:18, 18.33it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=44 Accuracy=9.38:  11%|█▏        | 44/391 [00:02<00:18, 18.33it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=44 Accuracy=9.38:  12%|█▏        | 45/391 [00:02<00:17, 19.51it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=44 Accuracy=9.38:  12%|█▏        | 45/391 [00:02<00:17, 19.43it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=45 Accuracy=14.06:  12%|█▏        | 45/391 [00:02<00:17, 19.43it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=46 Accuracy=7.03:  12%|█▏        | 46/391 [00:02<00:17, 19.43it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=47 Accuracy=10.16:  12%|█▏        | 47/391 [00:02<00:17, 19.43it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=47 Accuracy=10.16:  12%|█▏        | 48/391 [00:02<00:17, 20.13it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=47 Accuracy=10.16:  12%|█▏        | 48/391 [00:02<00:17, 20.05it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=48 Accuracy=10.16:  12%|█▏        | 48/391 [00:02<00:17, 20.05it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=49 Accuracy=9.38:  13%|█▎        | 49/391 [00:02<00:17, 20.05it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=50 Accuracy=10.16:  13%|█▎        | 50/391 [00:02<00:17, 20.05it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=50 Accuracy=10.16:  13%|█▎        | 51/391 [00:02<00:17, 19.59it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=50 Accuracy=10.16:  13%|█▎        | 51/391 [00:02<00:17, 19.51it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=51 Accuracy=14.84:  13%|█▎        | 51/391 [00:02<00:17, 19.51it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=52 Accuracy=9.38:  13%|█▎        | 52/391 [00:03<00:17, 19.51it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=53 Accuracy=12.50:  14%|█▎        | 53/391 [00:03<00:17, 19.51it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=53 Accuracy=12.50:  14%|█▍        | 54/391 [00:03<00:16, 20.05it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=53 Accuracy=12.50:  14%|█▍        | 54/391 [00:03<00:17, 19.71it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=54 Accuracy=10.94:  14%|█▍        | 54/391 [00:03<00:17, 19.71it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=55 Accuracy=8.59:  14%|█▍        | 55/391 [00:03<00:17, 19.71it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=56 Accuracy=7.03:  14%|█▍        | 56/391 [00:03<00:16, 19.71it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=56 Accuracy=7.03:  15%|█▍        | 57/391 [00:03<00:17, 19.35it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=56 Accuracy=7.03:  15%|█▍        | 57/391 [00:03<00:17, 19.06it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=57 Accuracy=9.38:  15%|█▍        | 57/391 [00:03<00:17, 19.06it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=58 Accuracy=6.25:  15%|█▍        | 58/391 [00:03<00:17, 19.06it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=59 Accuracy=13.28:  15%|█▌        | 59/391 [00:03<00:17, 19.06it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=59 Accuracy=13.28:  15%|█▌        | 60/391 [00:03<00:16, 19.55it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=59 Accuracy=13.28:  15%|█▌        | 60/391 [00:03<00:17, 19.33it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=60 Accuracy=8.59:  15%|█▌        | 60/391 [00:03<00:17, 19.33it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=61 Accuracy=10.94:  16%|█▌        | 61/391 [00:03<00:17, 19.33it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=61 Accuracy=10.94:  16%|█▌        | 62/391 [00:03<00:18, 18.26it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=61 Accuracy=10.94:  16%|█▌        | 62/391 [00:03<00:18, 18.09it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=62 Accuracy=8.59:  16%|█▌        | 62/391 [00:03<00:18, 18.09it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=63 Accuracy=14.84:  16%|█▌        | 63/391 [00:03<00:18, 18.09it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=63 Accuracy=14.84:  16%|█▋        | 64/391 [00:03<00:18, 17.83it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=63 Accuracy=14.84:  16%|█▋        | 64/391 [00:03<00:18, 17.60it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=64 Accuracy=10.16:  16%|█▋        | 64/391 [00:03<00:18, 17.60it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=65 Accuracy=12.50:  17%|█▋        | 65/391 [00:03<00:18, 17.60it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=65 Accuracy=12.50:  17%|█▋        | 66/391 [00:03<00:18, 17.67it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=65 Accuracy=12.50:  17%|█▋        | 66/391 [00:03<00:18, 17.51it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=66 Accuracy=8.59:  17%|█▋        | 66/391 [00:03<00:18, 17.51it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=67 Accuracy=10.16:  17%|█▋        | 67/391 [00:03<00:18, 17.51it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=67 Accuracy=10.16:  17%|█▋        | 68/391 [00:03<00:17, 18.16it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=67 Accuracy=10.16:  17%|█▋        | 68/391 [00:03<00:17, 17.96it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=68 Accuracy=9.38:  17%|█▋        | 68/391 [00:03<00:17, 17.96it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=69 Accuracy=5.47:  18%|█▊        | 69/391 [00:03<00:17, 17.96it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=69 Accuracy=5.47:  18%|█▊        | 70/391 [00:03<00:17, 18.31it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=69 Accuracy=5.47:  18%|█▊        | 70/391 [00:03<00:17, 18.07it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=70 Accuracy=8.59:  18%|█▊        | 70/391 [00:04<00:17, 18.07it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=71 Accuracy=12.50:  18%|█▊        | 71/391 [00:04<00:17, 18.07it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=72 Accuracy=8.59:  18%|█▊        | 72/391 [00:04<00:17, 18.07it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=72 Accuracy=8.59:  19%|█▊        | 73/391 [00:04<00:16, 19.15it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=72 Accuracy=8.59:  19%|█▊        | 73/391 [00:04<00:16, 18.96it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=73 Accuracy=12.50:  19%|█▊        | 73/391 [00:04<00:16, 18.96it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=74 Accuracy=10.16:  19%|█▉        | 74/391 [00:04<00:16, 18.96it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=75 Accuracy=6.25:  19%|█▉        | 75/391 [00:04<00:16, 18.96it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=75 Accuracy=6.25:  19%|█▉        | 76/391 [00:04<00:15, 20.15it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=75 Accuracy=6.25:  19%|█▉        | 76/391 [00:04<00:15, 19.93it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=76 Accuracy=15.62:  19%|█▉        | 76/391 [00:04<00:15, 19.93it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=77 Accuracy=15.62:  20%|█▉        | 77/391 [00:04<00:15, 19.93it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=78 Accuracy=9.38:  20%|█▉        | 78/391 [00:04<00:15, 19.93it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=78 Accuracy=9.38:  20%|██        | 79/391 [00:04<00:15, 19.96it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=78 Accuracy=9.38:  20%|██        | 79/391 [00:04<00:15, 19.63it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=79 Accuracy=11.72:  20%|██        | 79/391 [00:04<00:15, 19.63it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=80 Accuracy=3.91:  20%|██        | 80/391 [00:04<00:15, 19.63it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=81 Accuracy=9.38:  21%|██        | 81/391 [00:04<00:15, 19.63it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=81 Accuracy=9.38:  21%|██        | 82/391 [00:04<00:16, 19.08it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=81 Accuracy=9.38:  21%|██        | 82/391 [00:04<00:16, 18.85it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=82 Accuracy=7.81:  21%|██        | 82/391 [00:04<00:16, 18.85it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=83 Accuracy=10.16:  21%|██        | 83/391 [00:04<00:16, 18.85it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=83 Accuracy=10.16:  21%|██▏       | 84/391 [00:04<00:16, 18.34it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=83 Accuracy=10.16:  21%|██▏       | 84/391 [00:04<00:17, 17.97it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=84 Accuracy=14.84:  21%|██▏       | 84/391 [00:04<00:17, 17.97it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=85 Accuracy=9.38:  22%|██▏       | 85/391 [00:04<00:17, 17.97it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=86 Accuracy=8.59:  22%|██▏       | 86/391 [00:04<00:16, 17.97it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=86 Accuracy=8.59:  22%|██▏       | 87/391 [00:04<00:16, 18.61it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=86 Accuracy=8.59:  22%|██▏       | 87/391 [00:04<00:16, 18.46it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=87 Accuracy=11.72:  22%|██▏       | 87/391 [00:04<00:16, 18.46it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=88 Accuracy=10.94:  23%|██▎       | 88/391 [00:04<00:16, 18.46it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=89 Accuracy=7.03:  23%|██▎       | 89/391 [00:05<00:16, 18.46it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=89 Accuracy=7.03:  23%|██▎       | 90/391 [00:05<00:15, 18.92it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=89 Accuracy=7.03:  23%|██▎       | 90/391 [00:05<00:16, 18.79it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=90 Accuracy=4.69:  23%|██▎       | 90/391 [00:05<00:16, 18.79it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=91 Accuracy=8.59:  23%|██▎       | 91/391 [00:05<00:15, 18.79it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=92 Accuracy=7.81:  24%|██▎       | 92/391 [00:05<00:15, 18.79it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=92 Accuracy=7.81:  24%|██▍       | 93/391 [00:05<00:15, 19.56it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=92 Accuracy=7.81:  24%|██▍       | 93/391 [00:05<00:15, 19.41it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=93 Accuracy=12.50:  24%|██▍       | 93/391 [00:05<00:15, 19.41it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=94 Accuracy=7.81:  24%|██▍       | 94/391 [00:05<00:15, 19.41it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=95 Accuracy=10.16:  24%|██▍       | 95/391 [00:05<00:15, 19.41it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=95 Accuracy=10.16:  25%|██▍       | 96/391 [00:05<00:15, 19.09it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=95 Accuracy=10.16:  25%|██▍       | 96/391 [00:05<00:15, 18.90it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=96 Accuracy=9.38:  25%|██▍       | 96/391 [00:05<00:15, 18.90it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=97 Accuracy=10.16:  25%|██▍       | 97/391 [00:05<00:15, 18.90it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=97 Accuracy=10.16:  25%|██▌       | 98/391 [00:05<00:15, 19.04it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=97 Accuracy=10.16:  25%|██▌       | 98/391 [00:05<00:15, 18.80it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=98 Accuracy=11.72:  25%|██▌       | 98/391 [00:05<00:15, 18.80it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=99 Accuracy=7.03:  25%|██▌       | 99/391 [00:05<00:15, 18.80it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=99 Accuracy=7.03:  26%|██▌       | 100/391 [00:05<00:15, 18.87it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=99 Accuracy=7.03:  26%|██▌       | 100/391 [00:05<00:15, 18.57it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=100 Accuracy=8.59:  26%|██▌       | 100/391 [00:05<00:15, 18.57it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=101 Accuracy=14.06:  26%|██▌       | 101/391 [00:05<00:15, 18.57it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=101 Accuracy=14.06:  26%|██▌       | 102/391 [00:05<00:16, 17.08it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=101 Accuracy=14.06:  26%|██▌       | 102/391 [00:05<00:17, 16.73it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=102 Accuracy=9.38:  26%|██▌       | 102/391 [00:05<00:17, 16.73it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=103 Accuracy=7.81:  26%|██▋       | 103/391 [00:05<00:17, 16.73it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=103 Accuracy=7.81:  27%|██▋       | 104/391 [00:05<00:16, 17.42it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=103 Accuracy=7.81:  27%|██▋       | 104/391 [00:05<00:16, 17.21it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=104 Accuracy=9.38:  27%|██▋       | 104/391 [00:05<00:16, 17.21it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=105 Accuracy=10.16:  27%|██▋       | 105/391 [00:05<00:16, 17.21it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=106 Accuracy=8.59:  27%|██▋       | 106/391 [00:05<00:16, 17.21it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=106 Accuracy=8.59:  27%|██▋       | 107/391 [00:05<00:15, 18.79it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=106 Accuracy=8.59:  27%|██▋       | 107/391 [00:05<00:15, 18.63it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=107 Accuracy=8.59:  27%|██▋       | 107/391 [00:05<00:15, 18.63it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=108 Accuracy=7.81:  28%|██▊       | 108/391 [00:06<00:15, 18.63it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=109 Accuracy=11.72:  28%|██▊       | 109/391 [00:06<00:15, 18.63it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=109 Accuracy=11.72:  28%|██▊       | 110/391 [00:06<00:14, 19.34it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=109 Accuracy=11.72:  28%|██▊       | 110/391 [00:06<00:14, 19.17it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=110 Accuracy=10.94:  28%|██▊       | 110/391 [00:06<00:14, 19.17it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=111 Accuracy=8.59:  28%|██▊       | 111/391 [00:06<00:14, 19.17it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=112 Accuracy=14.06:  29%|██▊       | 112/391 [00:06<00:14, 19.17it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=112 Accuracy=14.06:  29%|██▉       | 113/391 [00:06<00:14, 19.86it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=112 Accuracy=14.06:  29%|██▉       | 113/391 [00:06<00:14, 19.69it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=113 Accuracy=6.25:  29%|██▉       | 113/391 [00:06<00:14, 19.69it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=114 Accuracy=7.81:  29%|██▉       | 114/391 [00:06<00:14, 19.69it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=115 Accuracy=8.59:  29%|██▉       | 115/391 [00:06<00:14, 19.69it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=115 Accuracy=8.59:  30%|██▉       | 116/391 [00:06<00:14, 19.56it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=115 Accuracy=8.59:  30%|██▉       | 116/391 [00:06<00:14, 19.41it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=116 Accuracy=10.94:  30%|██▉       | 116/391 [00:06<00:14, 19.41it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=117 Accuracy=12.50:  30%|██▉       | 117/391 [00:06<00:14, 19.41it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=117 Accuracy=12.50:  30%|███       | 118/391 [00:06<00:14, 18.44it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=117 Accuracy=12.50:  30%|███       | 118/391 [00:06<00:14, 18.24it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=118 Accuracy=10.94:  30%|███       | 118/391 [00:06<00:14, 18.24it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=119 Accuracy=12.50:  30%|███       | 119/391 [00:06<00:14, 18.24it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=119 Accuracy=12.50:  31%|███       | 120/391 [00:06<00:15, 17.97it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=119 Accuracy=12.50:  31%|███       | 120/391 [00:06<00:15, 17.59it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=120 Accuracy=7.81:  31%|███       | 120/391 [00:06<00:15, 17.59it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=121 Accuracy=7.81:  31%|███       | 121/391 [00:06<00:15, 17.59it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=122 Accuracy=10.94:  31%|███       | 122/391 [00:06<00:15, 17.59it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=122 Accuracy=10.94:  31%|███▏      | 123/391 [00:06<00:14, 18.75it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=122 Accuracy=10.94:  31%|███▏      | 123/391 [00:06<00:14, 18.62it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=123 Accuracy=11.72:  31%|███▏      | 123/391 [00:06<00:14, 18.62it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=124 Accuracy=11.72:  32%|███▏      | 124/391 [00:06<00:14, 18.62it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=124 Accuracy=11.72:  32%|███▏      | 125/391 [00:06<00:14, 18.61it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=124 Accuracy=11.72:  32%|███▏      | 125/391 [00:06<00:14, 18.31it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=125 Accuracy=13.28:  32%|███▏      | 125/391 [00:06<00:14, 18.31it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=126 Accuracy=8.59:  32%|███▏      | 126/391 [00:06<00:14, 18.31it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=126 Accuracy=8.59:  32%|███▏      | 127/391 [00:06<00:14, 18.34it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=126 Accuracy=8.59:  32%|███▏      | 127/391 [00:06<00:14, 18.08it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=127 Accuracy=10.94:  32%|███▏      | 127/391 [00:07<00:14, 18.08it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=128 Accuracy=10.94:  33%|███▎      | 128/391 [00:07<00:14, 18.08it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=129 Accuracy=10.94:  33%|███▎      | 129/391 [00:07<00:14, 18.08it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=129 Accuracy=10.94:  33%|███▎      | 130/391 [00:07<00:13, 19.55it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=129 Accuracy=10.94:  33%|███▎      | 130/391 [00:07<00:13, 19.42it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=130 Accuracy=12.50:  33%|███▎      | 130/391 [00:07<00:13, 19.42it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=131 Accuracy=11.72:  34%|███▎      | 131/391 [00:07<00:13, 19.42it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=132 Accuracy=6.25:  34%|███▍      | 132/391 [00:07<00:13, 19.42it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=132 Accuracy=6.25:  34%|███▍      | 133/391 [00:07<00:13, 19.84it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=132 Accuracy=6.25:  34%|███▍      | 133/391 [00:07<00:13, 19.70it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=133 Accuracy=9.38:  34%|███▍      | 133/391 [00:07<00:13, 19.70it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=134 Accuracy=10.16:  34%|███▍      | 134/391 [00:07<00:13, 19.70it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=135 Accuracy=5.47:  35%|███▍      | 135/391 [00:07<00:12, 19.70it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=135 Accuracy=5.47:  35%|███▍      | 136/391 [00:07<00:12, 19.62it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=135 Accuracy=5.47:  35%|███▍      | 136/391 [00:07<00:13, 19.53it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=136 Accuracy=7.03:  35%|███▍      | 136/391 [00:07<00:13, 19.53it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=137 Accuracy=10.94:  35%|███▌      | 137/391 [00:07<00:13, 19.53it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=138 Accuracy=14.84:  35%|███▌      | 138/391 [00:07<00:12, 19.53it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=138 Accuracy=14.84:  36%|███▌      | 139/391 [00:07<00:12, 19.62it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=138 Accuracy=14.84:  36%|███▌      | 139/391 [00:07<00:12, 19.48it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=139 Accuracy=10.16:  36%|███▌      | 139/391 [00:07<00:12, 19.48it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=140 Accuracy=11.72:  36%|███▌      | 140/391 [00:07<00:12, 19.48it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=141 Accuracy=10.16:  36%|███▌      | 141/391 [00:07<00:12, 19.48it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=141 Accuracy=10.16:  36%|███▋      | 142/391 [00:07<00:12, 19.64it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=141 Accuracy=10.16:  36%|███▋      | 142/391 [00:07<00:12, 19.52it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=142 Accuracy=7.03:  36%|███▋      | 142/391 [00:07<00:12, 19.52it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=143 Accuracy=7.81:  37%|███▋      | 143/391 [00:07<00:12, 19.52it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=143 Accuracy=7.81:  37%|███▋      | 144/391 [00:07<00:12, 19.54it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=143 Accuracy=7.81:  37%|███▋      | 144/391 [00:07<00:12, 19.04it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=144 Accuracy=7.03:  37%|███▋      | 144/391 [00:07<00:12, 19.04it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=145 Accuracy=10.94:  37%|███▋      | 145/391 [00:07<00:12, 19.04it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=145 Accuracy=10.94:  37%|███▋      | 146/391 [00:07<00:12, 19.12it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=145 Accuracy=10.94:  37%|███▋      | 146/391 [00:07<00:12, 18.85it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=146 Accuracy=10.16:  37%|███▋      | 146/391 [00:08<00:12, 18.85it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=147 Accuracy=12.50:  38%|███▊      | 147/391 [00:08<00:12, 18.85it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=148 Accuracy=6.25:  38%|███▊      | 148/391 [00:08<00:12, 18.85it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=148 Accuracy=6.25:  38%|███▊      | 149/391 [00:08<00:12, 19.67it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=148 Accuracy=6.25:  38%|███▊      | 149/391 [00:08<00:12, 19.58it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=149 Accuracy=7.81:  38%|███▊      | 149/391 [00:08<00:12, 19.58it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=150 Accuracy=9.38:  38%|███▊      | 150/391 [00:08<00:12, 19.58it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=151 Accuracy=9.38:  39%|███▊      | 151/391 [00:08<00:12, 19.58it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=151 Accuracy=9.38:  39%|███▉      | 152/391 [00:08<00:11, 20.95it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=151 Accuracy=9.38:  39%|███▉      | 152/391 [00:08<00:11, 20.84it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=152 Accuracy=14.84:  39%|███▉      | 152/391 [00:08<00:11, 20.84it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=153 Accuracy=15.62:  39%|███▉      | 153/391 [00:08<00:11, 20.84it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=154 Accuracy=8.59:  39%|███▉      | 154/391 [00:08<00:11, 20.84it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=154 Accuracy=8.59:  40%|███▉      | 155/391 [00:08<00:11, 20.37it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=154 Accuracy=8.59:  40%|███▉      | 155/391 [00:08<00:11, 20.23it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=155 Accuracy=10.94:  40%|███▉      | 155/391 [00:08<00:11, 20.23it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=156 Accuracy=7.81:  40%|███▉      | 156/391 [00:08<00:11, 20.23it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=157 Accuracy=12.50:  40%|████      | 157/391 [00:08<00:11, 20.23it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=157 Accuracy=12.50:  40%|████      | 158/391 [00:08<00:11, 20.30it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=157 Accuracy=12.50:  40%|████      | 158/391 [00:08<00:11, 20.18it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=158 Accuracy=7.81:  40%|████      | 158/391 [00:08<00:11, 20.18it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=159 Accuracy=10.16:  41%|████      | 159/391 [00:08<00:11, 20.18it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=160 Accuracy=10.94:  41%|████      | 160/391 [00:08<00:11, 20.18it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=160 Accuracy=10.94:  41%|████      | 161/391 [00:08<00:11, 19.73it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=160 Accuracy=10.94:  41%|████      | 161/391 [00:08<00:11, 19.55it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=161 Accuracy=10.94:  41%|████      | 161/391 [00:08<00:11, 19.55it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=162 Accuracy=10.16:  41%|████▏     | 162/391 [00:08<00:11, 19.55it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=162 Accuracy=10.16:  42%|████▏     | 163/391 [00:08<00:11, 19.36it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=162 Accuracy=10.16:  42%|████▏     | 163/391 [00:08<00:11, 19.07it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=163 Accuracy=10.94:  42%|████▏     | 163/391 [00:08<00:11, 19.07it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=164 Accuracy=6.25:  42%|████▏     | 164/391 [00:08<00:11, 19.07it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=165 Accuracy=5.47:  42%|████▏     | 165/391 [00:08<00:11, 19.07it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=165 Accuracy=5.47:  42%|████▏     | 166/391 [00:08<00:11, 20.04it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=165 Accuracy=5.47:  42%|████▏     | 166/391 [00:08<00:11, 19.83it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=166 Accuracy=10.16:  42%|████▏     | 166/391 [00:08<00:11, 19.83it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=167 Accuracy=10.16:  43%|████▎     | 167/391 [00:09<00:11, 19.83it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=168 Accuracy=13.28:  43%|████▎     | 168/391 [00:09<00:11, 19.83it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=168 Accuracy=13.28:  43%|████▎     | 169/391 [00:09<00:10, 20.51it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=168 Accuracy=13.28:  43%|████▎     | 169/391 [00:09<00:10, 20.38it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=169 Accuracy=8.59:  43%|████▎     | 169/391 [00:09<00:10, 20.38it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=170 Accuracy=9.38:  43%|████▎     | 170/391 [00:09<00:10, 20.38it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=171 Accuracy=10.16:  44%|████▎     | 171/391 [00:09<00:10, 20.38it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=171 Accuracy=10.16:  44%|████▍     | 172/391 [00:09<00:10, 20.93it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=171 Accuracy=10.16:  44%|████▍     | 172/391 [00:09<00:10, 20.65it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=172 Accuracy=10.16:  44%|████▍     | 172/391 [00:09<00:10, 20.65it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=173 Accuracy=14.06:  44%|████▍     | 173/391 [00:09<00:10, 20.65it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=174 Accuracy=11.72:  45%|████▍     | 174/391 [00:09<00:10, 20.65it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=174 Accuracy=11.72:  45%|████▍     | 175/391 [00:09<00:10, 21.42it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=174 Accuracy=11.72:  45%|████▍     | 175/391 [00:09<00:10, 21.30it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=175 Accuracy=8.59:  45%|████▍     | 175/391 [00:09<00:10, 21.30it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=176 Accuracy=7.81:  45%|████▌     | 176/391 [00:09<00:10, 21.30it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=177 Accuracy=10.16:  45%|████▌     | 177/391 [00:09<00:10, 21.30it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=177 Accuracy=10.16:  46%|████▌     | 178/391 [00:09<00:09, 21.54it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=177 Accuracy=10.16:  46%|████▌     | 178/391 [00:09<00:09, 21.42it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=178 Accuracy=10.16:  46%|████▌     | 178/391 [00:09<00:09, 21.42it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=179 Accuracy=9.38:  46%|████▌     | 179/391 [00:09<00:09, 21.42it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=180 Accuracy=12.50:  46%|████▌     | 180/391 [00:09<00:09, 21.42it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=180 Accuracy=12.50:  46%|████▋     | 181/391 [00:09<00:09, 21.32it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=180 Accuracy=12.50:  46%|████▋     | 181/391 [00:09<00:09, 21.21it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=181 Accuracy=8.59:  46%|████▋     | 181/391 [00:09<00:09, 21.21it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=182 Accuracy=5.47:  47%|████▋     | 182/391 [00:09<00:09, 21.21it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=183 Accuracy=11.72:  47%|████▋     | 183/391 [00:09<00:09, 21.21it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=183 Accuracy=11.72:  47%|████▋     | 184/391 [00:09<00:10, 20.11it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=183 Accuracy=11.72:  47%|████▋     | 184/391 [00:09<00:10, 19.97it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=184 Accuracy=7.81:  47%|████▋     | 184/391 [00:09<00:10, 19.97it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=185 Accuracy=9.38:  47%|████▋     | 185/391 [00:09<00:10, 19.97it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=185 Accuracy=9.38:  48%|████▊     | 186/391 [00:09<00:10, 19.78it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=185 Accuracy=9.38:  48%|████▊     | 186/391 [00:09<00:10, 19.47it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=186 Accuracy=7.03:  48%|████▊     | 186/391 [00:09<00:10, 19.47it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=187 Accuracy=9.38:  48%|████▊     | 187/391 [00:10<00:10, 19.47it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=188 Accuracy=16.41:  48%|████▊     | 188/391 [00:10<00:10, 19.47it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=188 Accuracy=16.41:  48%|████▊     | 189/391 [00:10<00:10, 19.82it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=188 Accuracy=16.41:  48%|████▊     | 189/391 [00:10<00:10, 19.45it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=189 Accuracy=7.03:  48%|████▊     | 189/391 [00:10<00:10, 19.45it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=190 Accuracy=9.38:  49%|████▊     | 190/391 [00:10<00:10, 19.45it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=190 Accuracy=9.38:  49%|████▉     | 191/391 [00:10<00:10, 19.31it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=190 Accuracy=9.38:  49%|████▉     | 191/391 [00:10<00:10, 19.18it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=191 Accuracy=12.50:  49%|████▉     | 191/391 [00:10<00:10, 19.18it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=192 Accuracy=10.16:  49%|████▉     | 192/391 [00:10<00:10, 19.18it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=192 Accuracy=10.16:  49%|████▉     | 193/391 [00:10<00:10, 19.06it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=192 Accuracy=10.16:  49%|████▉     | 193/391 [00:10<00:10, 18.92it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=193 Accuracy=8.59:  49%|████▉     | 193/391 [00:10<00:10, 18.92it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=194 Accuracy=7.81:  50%|████▉     | 194/391 [00:10<00:10, 18.92it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=195 Accuracy=13.28:  50%|████▉     | 195/391 [00:10<00:10, 18.92it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=195 Accuracy=13.28:  50%|█████     | 196/391 [00:10<00:10, 19.18it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=195 Accuracy=13.28:  50%|█████     | 196/391 [00:10<00:10, 18.99it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=196 Accuracy=8.59:  50%|█████     | 196/391 [00:10<00:10, 18.99it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=197 Accuracy=10.16:  50%|█████     | 197/391 [00:10<00:10, 18.99it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=197 Accuracy=10.16:  51%|█████     | 198/391 [00:10<00:10, 18.57it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=197 Accuracy=10.16:  51%|█████     | 198/391 [00:10<00:10, 18.32it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=198 Accuracy=7.81:  51%|█████     | 198/391 [00:10<00:10, 18.32it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=199 Accuracy=5.47:  51%|█████     | 199/391 [00:10<00:10, 18.32it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=199 Accuracy=5.47:  51%|█████     | 200/391 [00:10<00:10, 18.32it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=199 Accuracy=5.47:  51%|█████     | 200/391 [00:10<00:10, 18.07it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=200 Accuracy=10.16:  51%|█████     | 200/391 [00:10<00:10, 18.07it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=201 Accuracy=12.50:  51%|█████▏    | 201/391 [00:10<00:10, 18.07it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=202 Accuracy=11.72:  52%|█████▏    | 202/391 [00:10<00:10, 18.07it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=202 Accuracy=11.72:  52%|█████▏    | 203/391 [00:10<00:10, 18.56it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=202 Accuracy=11.72:  52%|█████▏    | 203/391 [00:10<00:10, 18.44it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=203 Accuracy=11.72:  52%|█████▏    | 203/391 [00:10<00:10, 18.44it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=204 Accuracy=13.28:  52%|█████▏    | 204/391 [00:10<00:10, 18.44it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=204 Accuracy=13.28:  52%|█████▏    | 205/391 [00:10<00:09, 18.87it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=204 Accuracy=13.28:  52%|█████▏    | 205/391 [00:10<00:09, 18.73it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=205 Accuracy=7.03:  52%|█████▏    | 205/391 [00:10<00:09, 18.73it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=206 Accuracy=10.16:  53%|█████▎    | 206/391 [00:11<00:09, 18.73it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=207 Accuracy=9.38:  53%|█████▎    | 207/391 [00:11<00:09, 18.73it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=207 Accuracy=9.38:  53%|█████▎    | 208/391 [00:11<00:09, 19.60it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=207 Accuracy=9.38:  53%|█████▎    | 208/391 [00:11<00:09, 19.44it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=208 Accuracy=10.94:  53%|█████▎    | 208/391 [00:11<00:09, 19.44it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=209 Accuracy=7.81:  53%|█████▎    | 209/391 [00:11<00:09, 19.44it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=210 Accuracy=7.03:  54%|█████▎    | 210/391 [00:11<00:09, 19.44it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=210 Accuracy=7.03:  54%|█████▍    | 211/391 [00:11<00:09, 18.36it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=210 Accuracy=7.03:  54%|█████▍    | 211/391 [00:11<00:09, 18.16it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=211 Accuracy=13.28:  54%|█████▍    | 211/391 [00:11<00:09, 18.16it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=212 Accuracy=6.25:  54%|█████▍    | 212/391 [00:11<00:09, 18.16it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=212 Accuracy=6.25:  54%|█████▍    | 213/391 [00:11<00:09, 18.52it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=212 Accuracy=6.25:  54%|█████▍    | 213/391 [00:11<00:09, 18.34it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=213 Accuracy=7.03:  54%|█████▍    | 213/391 [00:11<00:09, 18.34it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=214 Accuracy=12.50:  55%|█████▍    | 214/391 [00:11<00:09, 18.34it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=214 Accuracy=12.50:  55%|█████▍    | 215/391 [00:11<00:09, 18.29it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=214 Accuracy=12.50:  55%|█████▍    | 215/391 [00:11<00:09, 18.00it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=215 Accuracy=5.47:  55%|█████▍    | 215/391 [00:11<00:09, 18.00it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=216 Accuracy=7.03:  55%|█████▌    | 216/391 [00:11<00:09, 18.00it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=216 Accuracy=7.03:  55%|█████▌    | 217/391 [00:11<00:09, 18.34it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=216 Accuracy=7.03:  55%|█████▌    | 217/391 [00:11<00:09, 18.16it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=217 Accuracy=4.69:  55%|█████▌    | 217/391 [00:11<00:09, 18.16it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=218 Accuracy=10.94:  56%|█████▌    | 218/391 [00:11<00:09, 18.16it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=218 Accuracy=10.94:  56%|█████▌    | 219/391 [00:11<00:09, 18.32it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=218 Accuracy=10.94:  56%|█████▌    | 219/391 [00:11<00:09, 18.03it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=219 Accuracy=10.16:  56%|█████▌    | 219/391 [00:11<00:09, 18.03it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=220 Accuracy=12.50:  56%|█████▋    | 220/391 [00:11<00:09, 18.03it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=220 Accuracy=12.50:  57%|█████▋    | 221/391 [00:11<00:09, 18.44it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=220 Accuracy=12.50:  57%|█████▋    | 221/391 [00:11<00:09, 18.33it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=221 Accuracy=7.81:  57%|█████▋    | 221/391 [00:11<00:09, 18.33it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=222 Accuracy=7.81:  57%|█████▋    | 222/391 [00:11<00:09, 18.33it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=223 Accuracy=9.38:  57%|█████▋    | 223/391 [00:11<00:09, 18.33it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=223 Accuracy=9.38:  57%|█████▋    | 224/391 [00:11<00:08, 19.39it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=223 Accuracy=9.38:  57%|█████▋    | 224/391 [00:11<00:08, 19.29it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=224 Accuracy=9.38:  57%|█████▋    | 224/391 [00:11<00:08, 19.29it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=225 Accuracy=10.94:  58%|█████▊    | 225/391 [00:12<00:08, 19.29it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=226 Accuracy=9.38:  58%|█████▊    | 226/391 [00:12<00:08, 19.29it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=226 Accuracy=9.38:  58%|█████▊    | 227/391 [00:12<00:08, 19.64it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=226 Accuracy=9.38:  58%|█████▊    | 227/391 [00:12<00:08, 19.54it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=227 Accuracy=7.81:  58%|█████▊    | 227/391 [00:12<00:08, 19.54it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=228 Accuracy=9.38:  58%|█████▊    | 228/391 [00:12<00:08, 19.54it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=229 Accuracy=9.38:  59%|█████▊    | 229/391 [00:12<00:08, 19.54it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=229 Accuracy=9.38:  59%|█████▉    | 230/391 [00:12<00:08, 19.34it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=229 Accuracy=9.38:  59%|█████▉    | 230/391 [00:12<00:08, 19.15it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=230 Accuracy=10.16:  59%|█████▉    | 230/391 [00:12<00:08, 19.15it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=231 Accuracy=3.91:  59%|█████▉    | 231/391 [00:12<00:08, 19.15it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=231 Accuracy=3.91:  59%|█████▉    | 232/391 [00:12<00:08, 18.92it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=231 Accuracy=3.91:  59%|█████▉    | 232/391 [00:12<00:08, 18.68it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=232 Accuracy=10.94:  59%|█████▉    | 232/391 [00:12<00:08, 18.68it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=233 Accuracy=13.28:  60%|█████▉    | 233/391 [00:12<00:08, 18.68it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=233 Accuracy=13.28:  60%|█████▉    | 234/391 [00:12<00:08, 18.81it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=233 Accuracy=13.28:  60%|█████▉    | 234/391 [00:12<00:08, 18.66it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=234 Accuracy=8.59:  60%|█████▉    | 234/391 [00:12<00:08, 18.66it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=235 Accuracy=5.47:  60%|██████    | 235/391 [00:12<00:08, 18.66it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=236 Accuracy=12.50:  60%|██████    | 236/391 [00:12<00:08, 18.66it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=236 Accuracy=12.50:  61%|██████    | 237/391 [00:12<00:07, 19.59it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=236 Accuracy=12.50:  61%|██████    | 237/391 [00:12<00:07, 19.45it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=237 Accuracy=13.28:  61%|██████    | 237/391 [00:12<00:07, 19.45it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=238 Accuracy=10.94:  61%|██████    | 238/391 [00:12<00:07, 19.45it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=239 Accuracy=8.59:  61%|██████    | 239/391 [00:12<00:07, 19.45it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=239 Accuracy=8.59:  61%|██████▏   | 240/391 [00:12<00:07, 19.11it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=239 Accuracy=8.59:  61%|██████▏   | 240/391 [00:12<00:08, 18.77it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=240 Accuracy=5.47:  61%|██████▏   | 240/391 [00:12<00:08, 18.77it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=241 Accuracy=7.81:  62%|██████▏   | 241/391 [00:12<00:07, 18.77it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=241 Accuracy=7.81:  62%|██████▏   | 242/391 [00:12<00:08, 18.37it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=241 Accuracy=7.81:  62%|██████▏   | 242/391 [00:12<00:08, 18.24it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=242 Accuracy=11.72:  62%|██████▏   | 242/391 [00:12<00:08, 18.24it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=243 Accuracy=13.28:  62%|██████▏   | 243/391 [00:12<00:08, 18.24it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=244 Accuracy=10.94:  62%|██████▏   | 244/391 [00:13<00:08, 18.24it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=244 Accuracy=10.94:  63%|██████▎   | 245/391 [00:13<00:07, 19.40it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=244 Accuracy=10.94:  63%|██████▎   | 245/391 [00:13<00:07, 19.30it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=245 Accuracy=10.94:  63%|██████▎   | 245/391 [00:13<00:07, 19.30it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=246 Accuracy=14.84:  63%|██████▎   | 246/391 [00:13<00:07, 19.30it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=247 Accuracy=11.72:  63%|██████▎   | 247/391 [00:13<00:07, 19.30it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=247 Accuracy=11.72:  63%|██████▎   | 248/391 [00:13<00:07, 19.66it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=247 Accuracy=11.72:  63%|██████▎   | 248/391 [00:13<00:07, 19.35it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=248 Accuracy=11.72:  63%|██████▎   | 248/391 [00:13<00:07, 19.35it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=249 Accuracy=11.72:  64%|██████▎   | 249/391 [00:13<00:07, 19.35it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=250 Accuracy=8.59:  64%|██████▍   | 250/391 [00:13<00:07, 19.35it/s] \u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=250 Accuracy=8.59:  64%|██████▍   | 251/391 [00:13<00:07, 19.70it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=250 Accuracy=8.59:  64%|██████▍   | 251/391 [00:13<00:07, 19.54it/s]\u001b[A\n",
            "Epoch= 5 Loss=nan Batch_id=251 Accuracy=12.50:  64%|██████▍   | 251/391 [00:13<00:07, 19.54it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-fec82ebe8675>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mparam_group\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lr= \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam_group\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mtest_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Finished Training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gdrive/My Drive/TSAI_EVA_4.0/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, device, trainloader, optimizer, criterion, epoch)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSBshnxL8IdA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
